{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Practice for  FPM Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Exploring properties of the dataset T10I4D100K_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the head and tail of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 122 161 343 390 535 538 675 874 921 932 \r",
      "\r\n",
      "101 147 657 778 903 \r",
      "\r\n",
      "21 52 97 147 183 368 381 424 574 676 793 857 947 \r",
      "\r\n",
      "172 388 464 500 529 538 598 782 945 \r",
      "\r\n",
      "447 480 529 594 708 809 841 849 874 \r",
      "\r\n",
      "127 151 161 334 427 470 494 569 \r",
      "\r\n",
      "21 32 54 136 213 239 274 348 411 753 764 \r",
      "\r\n",
      "37 383 460 571 623 736 795 814 844 853 858 992 \r",
      "\r\n",
      "24 55 470 522 775 940 \r",
      "\r\n",
      "95 143 159 347 460 481 517 682 697 722 774 883 897 919 966 \r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head T10I4D100K_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of items in the data file T10I4D100K_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871\r\n"
     ]
    }
   ],
   "source": [
    "!awk -- '{for (i = 1; i <= NF; i++) wc[$i] += 1}; END {print length(wc)}' T10I4D100K_new.dat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of transactions in the data file T10I4D100K_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99936 T10I4D100K_new.dat\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l T10I4D100K_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generating frequent, maximal and closed itemsets using $\\color{red}{\\text{Apriori}}$ algorithm from the dataset T10I4D100K_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apriori Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the linux executable for apriori from here: http://www.borgelt.net/apriori.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ./apriori [options] infile [outfile]\r\n",
      "find frequent item sets with the apriori algorithm\r\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\r\n",
      "-t#      target type                              (default: s)\r\n",
      "         (s: frequent, c: closed, m: maximal item sets,\r\n",
      "          g: generators, r: association rules)\r\n",
      "-m#      minimum number of items per set/rule     (default: 1)\r\n",
      "-n#      maximum number of items per set/rule     (default: no limit)\r\n",
      "-s#      minimum support of an item set/rule      (default: 10%)\r\n",
      "-S#      maximum support of an item set/rule      (default: 100%)\r\n",
      "         (positive: percentage, negative: absolute number)\r\n",
      "-o       use original rule support definition     (body & head)\r\n",
      "-c#      minimum confidence of an assoc. rule     (default: 80%)\r\n",
      "-e#      additional evaluation measure            (default: none)\r\n",
      "-a#      aggregation mode for evaluation measure  (default: none)\r\n",
      "-d#      threshold for add. evaluation measure    (default: 10%)\r\n",
      "-i       invalidate eval. below expected support  (default: evaluate all)\r\n",
      "-p#      (min. size for) pruning with evaluation  (default: no pruning)\r\n",
      "         (< 0: weak forward, > 0 strong forward, = 0: backward pruning)\r\n",
      "-q#      sort items w.r.t. their frequency        (default: 2)\r\n",
      "         (1: ascending, -1: descending, 0: do not sort,\r\n",
      "          2: ascending, -2: descending w.r.t. transaction size sum)\r\n",
      "-u#      filter unused items from transactions    (default: 0.01)\r\n",
      "         (0: do not filter items w.r.t. usage in sets,\r\n",
      "         <0: fraction of removed items for filtering,\r\n",
      "         >0: take execution times ratio into account)\r\n",
      "-x       do not prune with perfect extensions     (default: prune)\r\n",
      "-y       a-posteriori pruning of infrequent item sets\r\n",
      "-T       do not organize transactions as a prefix tree\r\n",
      "-F#:#..  support border for filtering item sets   (default: none)\r\n",
      "         (list of minimum support values, one per item set size,\r\n",
      "         starting at the minimum size, as given with option -m#)\r\n",
      "-R#      read item selection/appearance indicators\r\n",
      "-P#      write a pattern spectrum to a file\r\n",
      "-Z       print item set statistics (number of item sets per size)\r\n",
      "-N       do not pre-format some integer numbers   (default: do)\r\n",
      "-g       write item names in scanable form (quote certain characters)\r\n",
      "-h#      record header  for output                (default: \"\")\r\n",
      "-k#      item separator for output                (default: \" \")\r\n",
      "-I#      implication sign for association rules   (default: \" <- \")\r\n",
      "-v#      output format for set/rule information   (default: \" (%S)\")\r\n",
      "-j#      sort item sets in output by their size   (default: no sorting)\r\n",
      "         (< 0: descending, > 0: ascending order)\r\n",
      "-w       integer transaction weight in last field (default: only items)\r\n",
      "-r#      record/transaction separators            (default: \"\\n\")\r\n",
      "-f#      field /item        separators            (default: \" \\t,\")\r\n",
      "-b#      blank   characters                       (default: \" \\t\\r\")\r\n",
      "-C#      comment characters                       (default: \"#\")\r\n",
      "-!       print additional option information\r\n",
      "infile   file to read transactions from           [required]\r\n",
      "outfile  file to write item sets/assoc. rules to  [optional]\r\n"
     ]
    }
   ],
   "source": [
    "!./apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the **frequent itemsets** with minsup = 100. Use option **-ts** for frequent itemsets and **-s-100** to indicate _minsup_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.06s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.02s].\n",
      "building transaction tree ... [112796 node(s)] done [0.02s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 done [0.32s].\n",
      "writing T_AP_Freq_S100.txt ... [27523 set(s)] done [0.00s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -ts -s-100 T10I4D100K_new.dat T_AP_Freq_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the patterns generated above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729 (102)\r\n",
      "199 (109)\r\n",
      "330 (102)\r\n",
      "62 (110)\r\n",
      "856 (109)\r\n",
      "856 490 906 (103)\r\n",
      "856 490 (103)\r\n",
      "856 906 (103)\r\n",
      "102 (109)\r\n",
      "228 (118)\r\n"
     ]
    }
   ],
   "source": [
    "!head T_AP_Freq_S100.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "766 (6261)\r\n",
      "766 829 (321)\r\n",
      "766 529 (317)\r\n",
      "766 368 (503)\r\n",
      "829 (6806)\r\n",
      "829 529 (583)\r\n",
      "829 368 (1193)\r\n",
      "529 (7050)\r\n",
      "529 368 (639)\r\n",
      "368 (7823)\r\n"
     ]
    }
   ],
   "source": [
    "!tail T_AP_Freq_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of frequent patterns in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27523 T_AP_Freq_S100.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l T_AP_Freq_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of frequent patterns for different itemset sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    797 1\r\n",
      "   8826 2\r\n",
      "   7128 3\r\n",
      "   5499 4\r\n",
      "   3187 5\r\n",
      "   1429 6\r\n",
      "    503 7\r\n",
      "    129 8\r\n",
      "     23 9\r\n",
      "      2 10\r\n"
     ]
    }
   ],
   "source": [
    "!awk '{print NF-1}' T_AP_Freq_S100.txt|sort -n|uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the time taken by apriori to generate frequent patterns. Here we do not write the patterns to a file to get the best estimate of time taken to discover frequent patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.07s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.02s].\n",
      "building transaction tree ... [112796 node(s)] done [0.01s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 done [0.32s].\n",
      "writing <null> ... [27523 set(s)] done [0.00s].\n",
      "0 secs  619789 microsecs\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "start = datetime.datetime.now()\n",
    "!./apriori -ts -s-100 T10I4D100K_new.dat \n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the **maximal frequent itemsets** with minsup = 100. Use **-tm** for *maximal* itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.08s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.02s].\n",
      "building transaction tree ... [112796 node(s)] done [0.01s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 done [0.32s].\n",
      "filtering for maximal item sets ... done [0.04s].\n",
      "writing T_AP_Maximal_S100.txt ... [4061 set(s)] done [0.00s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -tm -s-100 T10I4D100K_new.dat T_AP_Maximal_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the **closed itemsets** with minsup = 100. Use **-tc** for *closed* itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.08s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [112796 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 done [0.34s].\n",
      "filtering for closed item sets ... done [0.16s].\n",
      "writing T_AP_Closed_S100.txt ... [26797 set(s)] done [0.00s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -tc -s-100 T10I4D100K_new.dat T_AP_Closed_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating frequent, maximal and closed itemsets using $\\color{red}{\\text{ECLAT}}$ algorithm from the dataset T10I4D100K_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the linux executable for ECLAT from here: http://www.borgelt.net/eclat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x eclat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ./eclat [options] infile [outfile]\r\n",
      "find frequent item sets with the eclat algorithm\r\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\r\n",
      "-t#      target type                              (default: s)\r\n",
      "         (s: frequent, c: closed, m: maximal item sets,\r\n",
      "          g: generators, r: association rules)\r\n",
      "-m#      minimum number of items per set/rule     (default: 1)\r\n",
      "-n#      maximum number of items per set/rule     (default: no limit)\r\n",
      "-s#      minimum support of an item set/rule      (default: 10%)\r\n",
      "-S#      maximum support of an item set/rule      (default: 100%)\r\n",
      "         (positive: percentage, negative: absolute number)\r\n",
      "-o       use original rule support definition     (body & head)\r\n",
      "-c#      minimum confidence of an assoc. rule     (default: 80%)\r\n",
      "-e#      additional evaluation measure            (default: none)\r\n",
      "-a#      aggregation mode for evaluation measure  (default: none)\r\n",
      "-d#      threshold for add. evaluation measure    (default: 10%)\r\n",
      "-i       invalidate eval. below expected support  (default: evaluate all)\r\n",
      "-p#      (min. size for) pruning with evaluation  (default: no pruning)\r\n",
      "         (< 0: weak forward, > 0 strong forward, = 0: backward pruning)\r\n",
      "-q#      sort items w.r.t. their frequency        (default: 2)\r\n",
      "         (1: ascending, -1: descending, 0: do not sort,\r\n",
      "          2: ascending, -2: descending w.r.t. transaction size sum)\r\n",
      "-A#      variant of the eclat algorithm to use    (default: 'a')\r\n",
      "-x       do not prune with perfect extensions     (default: prune)\r\n",
      "-l#      number of items for k-items machine      (default: 16)\r\n",
      "         (only for algorithm variants i,r,o,   options -Ai/-Ar/-Ao)\r\n",
      "-j       do not sort items w.r.t. cond. support   (default: sort)\r\n",
      "         (only for algorithm variants i,b,t,d, options -Ai/-Ab/-At/-Ad)\r\n",
      "-y#      check extensions for closed/maximal sets (default: repository)\r\n",
      "         (0: horizontal, > 0: vertical representation)\r\n",
      "         (only with improved tid lists variant, option -Ai)\r\n",
      "-u       do not use head union tail (hut) pruning (default: use hut)\r\n",
      "         (only for maximal item sets, option -tm, not with option -Ab)\r\n",
      "-F#:#..  support border for filtering item sets   (default: none)\r\n",
      "         (list of minimum support values, one per item set size,\r\n",
      "         starting at the minimum size, as given with option -m#)\r\n",
      "-R#      read item selection/appearance indicators\r\n",
      "-P#      write a pattern spectrum to a file\r\n",
      "-Z       print item set statistics (number of item sets per size)\r\n",
      "-N       do not pre-format some integer numbers   (default: do)\r\n",
      "-g       write output in scanable form (quote certain characters)\r\n",
      "-h#      record header  for output                (default: \"\")\r\n",
      "-k#      item separator for output                (default: \" \")\r\n",
      "-I#      implication sign for association rules   (default: \" <- \")\r\n",
      "-v#      output format for item set information   (default: \" (%S)\")\r\n",
      "-w       transaction weight in last field         (default: only items)\r\n",
      "-r#      record/transaction separators            (default: \"\\n\")\r\n",
      "-f#      field /item        separators            (default: \" \\t,\")\r\n",
      "-b#      blank   characters                       (default: \" \\t\\r\")\r\n",
      "-C#      comment characters                       (default: \"#\")\r\n",
      "-T#      file to write transaction identifiers to (default: none)\r\n",
      "-!       print additional option information\r\n",
      "infile   file to read transactions from           [required]\r\n",
      "outfile  file to write item sets/assoc.rules to   [optional]\r\n"
     ]
    }
   ],
   "source": [
    "!./eclat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating **Frequent Itemsets** with minsup = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.07s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.02s].\n",
      "writing T_EC_Freq_S100.txt ... [27523 set(s)] done [0.12s].\n"
     ]
    }
   ],
   "source": [
    "!./eclat -ts -s-100 T10I4D100K_new.dat T_EC_Freq_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the **Maximal Itemsets** with minsup = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.08s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.03s].\n",
      "writing T_EC_Maximal_S100.txt ... [4061 set(s)] done [0.14s].\n"
     ]
    }
   ],
   "source": [
    "!./eclat -tm -s-100 T10I4D100K_new.dat T_EC_Maximal_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating **Closed Itemsets** with minsup = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.05s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.01s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.03s].\n",
      "writing T_EC_Closed_S100.txt ... [26797 set(s)] done [0.10s].\n"
     ]
    }
   ],
   "source": [
    "!./eclat -tc -s-100 T10I4D100K_new.dat T_EC_Closed_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generating frequent, maximal and closed itemsets using $\\color{red}{\\text{FPGrowth}}$ algorithm from the dataset T10I4D100K_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the linux executable for FPGrowth from here: http://www.borgelt.net/fpgrowth.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x fpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ./fpgrowth [options] infile [outfile]\r\n",
      "find frequent item sets with the fpgrowth algorithm\r\n",
      "version 6.17 (2017.05.30)        (c) 2004-2017   Christian Borgelt\r\n",
      "-t#      target type                              (default: s)\r\n",
      "         (s: frequent, c: closed, m: maximal item sets,\r\n",
      "          g: generators, r: association rules)\r\n",
      "-m#      minimum number of items per set/rule     (default: 1)\r\n",
      "-n#      maximum number of items per set/rule     (default: no limit)\r\n",
      "-s#      minimum support of an item set/rule      (default: 10%)\r\n",
      "-S#      maximum support of an item set/rule      (default: 100%)\r\n",
      "         (positive: percentage, negative: absolute number)\r\n",
      "-o       use original rule support definition     (body & head)\r\n",
      "-c#      minimum confidence of an assoc. rule     (default: 80%)\r\n",
      "-e#      additional evaluation measure            (default: none)\r\n",
      "-a#      aggregation mode for evaluation measure  (default: none)\r\n",
      "-d#      threshold for add. evaluation measure    (default: 10%)\r\n",
      "-i       invalidate eval. below expected support  (default: evaluate all)\r\n",
      "-p#      (min. size for) pruning with evaluation  (default: no pruning)\r\n",
      "         (< 0: weak forward, > 0 strong forward, = 0: backward pruning)\r\n",
      "-q#      sort items w.r.t. their frequency        (default: 2)\r\n",
      "         (1: ascending, -1: descending, 0: do not sort,\r\n",
      "          2: ascending, -2: descending w.r.t. transaction size sum)\r\n",
      "-A#      variant of the fpgrowth algorithm to use (default: c)\r\n",
      "-x       do not prune with perfect extensions     (default: prune)\r\n",
      "-l#      number of items for k-items machine      (default: 16)\r\n",
      "         (only for variants s and d, options -As or -Ad)\r\n",
      "-j       do not sort items w.r.t. cond. support   (default: sort)\r\n",
      "         (only for algorithm variant c, option -Ac)\r\n",
      "-u       do not use head union tail (hut) pruning (default: use hut)\r\n",
      "         (only for maximal item sets, option -tm)\r\n",
      "-F#:#..  support border for filtering item sets   (default: none)\r\n",
      "         (list of minimum support values, one per item set size,\r\n",
      "         starting at the minimum size, as given with option -m#)\r\n",
      "-R#      read item selection/appearance indicators\r\n",
      "-P#      write a pattern spectrum to a file\r\n",
      "-Z       print item set statistics (number of item sets per size)\r\n",
      "-N       do not pre-format some integer numbers   (default: do)\r\n",
      "-g       write item names in scanable form (quote certain characters)\r\n",
      "-h#      record header  for output                (default: \"\")\r\n",
      "-k#      item separator for output                (default: \" \")\r\n",
      "-I#      implication sign for association rules   (default: \" <- \")\r\n",
      "-v#      output format for set/rule information   (default: \" (%S)\")\r\n",
      "-w       integer transaction weight in last field (default: only items)\r\n",
      "-r#      record/transaction separators            (default: \"\\n\")\r\n",
      "-f#      field /item        separators            (default: \" \\t,\")\r\n",
      "-b#      blank   characters                       (default: \" \\t\\r\")\r\n",
      "-C#      comment characters                       (default: \"#\")\r\n",
      "-!       print additional option information\r\n",
      "infile   file to read transactions from           [required]\r\n",
      "outfile  file to write item sets/assoc. rules to  [optional]\r\n"
     ]
    }
   ],
   "source": [
    "!./fpgrowth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating **frequent Itemsets** with minsup = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.17 (2017.05.30)        (c) 2004-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.07s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.02s].\n",
      "writing T_FP_Freq_S100.txt ... [27523 set(s)] done [0.17s].\n"
     ]
    }
   ],
   "source": [
    "!./fpgrowth -ts -s-100 T10I4D100K_new.dat T_FP_Freq_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating **maximal Itemsets** with minsup = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.17 (2017.05.30)        (c) 2004-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.06s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.02s].\n",
      "writing T_FP_Maximal_S100.txt ... [4061 set(s)] done [0.17s].\n"
     ]
    }
   ],
   "source": [
    "!./fpgrowth -tm -s-100 T10I4D100K_new.dat T_FP_Maximal_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating **closed Itemsets** with minsup = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.17 (2017.05.30)        (c) 2004-2017   Christian Borgelt\n",
      "reading T10I4D100K_new.dat ... [870 item(s), 99936 transaction(s)] done [0.06s].\n",
      "filtering, sorting and recoding items ... [797 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [89066/99936 transaction(s)] done [0.02s].\n",
      "writing T_FP_Closed_S100.txt ... [26797 set(s)] done [0.17s].\n"
     ]
    }
   ],
   "source": [
    "!./fpgrowth -tc -s-100 T10I4D100K_new.dat T_FP_Closed_S100.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing the run time of the three algorithms: Apriori, ECLAT, FPGrowth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numnber of Frequent Itemsets generated at each Frequency Count:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Frequency Count          |Itemsets Generated  |   \n",
    "|----------------------------|--------------------|     \n",
    "|10                          |410920              |  \n",
    "|100                         |27523               | \n",
    "|1000                        |385                 |   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time taken by each algorithm to generate the frequent itemsets at different frequency counts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Algorithm                |minsup=10           |minsup=100          |minsup=1000         |\n",
    "|----------------------------|--------------------|--------------------|--------------------|    \n",
    "|Apriori                     |1.88                |0.68                |0.32                |\n",
    "|Eclat                       |0.68                |0.46                |0.33                |\n",
    "|FPGrowth                    |0.86                |0.57                |0.40                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eclat algorithm, out of the three algorithms takes least time to generate the frequent itemsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sequence Mining: Finding subsequences that are frequent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PrefixSpan is another name for the projection based approach for discovering frequent subsequences. The implementation of prefixspan is available here: https://code.google.com/archive/p/prefixspan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x prefixspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrefixSpan version 1.00 - Sequential Pattern Miner\r\n",
      "Written by Yasuo Tabei\r\n",
      "\r\n",
      "\r\n",
      "Usage: prefixspan [OPTION]... INFILE\r\n",
      "\r\n",
      "       where [OPTION]...  is a list of zero or more optional arguments\r\n",
      "             INFILE(s)    is the name of the input transaction database\r\n",
      "\r\n",
      "Additional arguments (at most one input file may be specified):\r\n",
      "       -min_sup [minimum support]\r\n",
      "       -max_pat [maximum pattern]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!./prefixspan_ver1.1/prefixspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrefixSpan version 1.00 - Sequential Pattern Miner\r\n",
      "Written by Yasuo Tabei\r\n",
      "\r\n",
      "\r\n",
      "Usage: prefixspan [OPTION]... INFILE\r\n",
      "\r\n",
      "       where [OPTION]...  is a list of zero or more optional arguments\r\n",
      "             INFILE(s)    is the name of the input transaction database\r\n",
      "\r\n",
      "Additional arguments (at most one input file may be specified):\r\n",
      "       -min_sup [minimum support]\r\n",
      "       -max_pat [maximum pattern]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!./prefixspan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data from **in-class activities** on sequence mining: \n",
    "Find frequent sequences from the following sequence DB using a level-wise approach. Use minsup=3.\n",
    "Database: ABCAA, CBCBA, CBABA, CCABA, BAACB, ACACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 1 1\r\n",
      "3 2 3 2 1\r\n",
      "3 2 1 2 1\r\n",
      "3 3 1 2 1\r\n",
      "2 1 1 3 2\r\n",
      "1 3 1 3 3\r\n"
     ]
    }
   ],
   "source": [
    "!cat activities_data.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrefixSpan version 1.00 - Sequential Pattern Miner\r\n",
      "Written by Yasuo Tabei\r\n",
      "\r\n",
      "\r\n",
      "( 0 1 2 3 4 5 ) : 6\r\n",
      "1 \r\n",
      "( 0 1 2 3 4 5 ) : 6\r\n",
      "1 1 \r\n",
      "( 0 2 3 4 5 ) : 5\r\n",
      "1 2 \r\n",
      "( 0 2 3 4 ) : 4\r\n",
      "1 2 1 \r\n",
      "( 0 2 3 ) : 3\r\n",
      "1 3 \r\n",
      "( 0 4 5 ) : 3\r\n",
      "2 \r\n",
      "( 0 1 2 3 4 ) : 5\r\n",
      "2 1 \r\n",
      "( 0 1 2 3 4 ) : 5\r\n",
      "2 1 1 \r\n",
      "( 0 2 4 ) : 3\r\n",
      "2 2 \r\n",
      "( 1 2 4 ) : 3\r\n",
      "2 3 \r\n",
      "( 0 1 4 ) : 3\r\n",
      "3 \r\n",
      "( 0 1 2 3 4 5 ) : 6\r\n",
      "3 1 \r\n",
      "( 0 1 2 3 5 ) : 5\r\n",
      "3 1 1 \r\n",
      "( 0 2 3 ) : 3\r\n",
      "3 2 \r\n",
      "( 1 2 3 4 ) : 4\r\n",
      "3 2 1 \r\n",
      "( 1 2 3 ) : 3\r\n",
      "3 3 \r\n",
      "( 1 3 5 ) : 3\r\n"
     ]
    }
   ],
   "source": [
    "!./prefixspan -min_sup 3 activities_data.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing only the subsequences without the supporting transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrefixSpan version 1.00 - Sequential Pattern Miner\r\n",
      "Written by Yasuo Tabei\r\n",
      "\r\n",
      "\r\n",
      "1 \r\n",
      "1 1 \r\n",
      "1 2 \r\n",
      "1 2 1 \r\n",
      "1 3 \r\n",
      "2 \r\n",
      "2 1 \r\n",
      "2 1 1 \r\n",
      "2 2 \r\n",
      "2 3 \r\n",
      "3 \r\n",
      "3 1 \r\n",
      "3 1 1 \r\n",
      "3 2 \r\n",
      "3 2 1 \r\n",
      "3 3 \r\n"
     ]
    }
   ],
   "source": [
    "!./prefixspan -min_sup 3 activities_data.dat| sed -n 'p;n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the frequent subsequences to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrefixSpan version 1.00 - Sequential Pattern Miner\r\n",
      "Written by Yasuo Tabei\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!./prefixspan -min_sup 3 activities_data.dat| sed -n 'p;n'> subseq_activities_data_minsup_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 \r\n",
      "2 1 1 \r\n",
      "2 2 \r\n",
      "2 3 \r\n",
      "3 \r\n",
      "3 1 \r\n",
      "3 1 1 \r\n",
      "3 2 \r\n",
      "3 2 1 \r\n",
      "3 3 \r\n"
     ]
    }
   ],
   "source": [
    "!tail subseq_activities_data_minsup_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Sequence Mining: discovering frequent substrings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substring mining code is available here: http://www.borgelt.net/seqwog.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x seqwog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ./seqwog [options] infile [outfile]\r\n",
      "find frequent sequences without gaps\r\n",
      "version 3.16 (2016.10.15)        (c) 2010-2016   Christian Borgelt\r\n",
      "-t#      target type                              (default: s)\r\n",
      "         (s: frequent, c: closed, m: maximal sequences, r: rules)\r\n",
      "         (target type 'r' implies -a (all occurrences))\r\n",
      "-m#      minimum number of items per sequence     (default: 1)\r\n",
      "-n#      maximum number of items per sequence     (default: no limit)\r\n",
      "-s#      minimum support of a sequence            (default: 10%)\r\n",
      "         (positive: percentage, negative: absolute number)\r\n",
      "-o       use original rule support definition     (body & head)\r\n",
      "-c#      minimum confidence of a     rule         (default: 80%)\r\n",
      "-a       count all occurrences of a pattern       (default: #sequences)\r\n",
      "-F#:#..  support border for filtering item sets   (default: none)\r\n",
      "         (list of minimum support values, one per item set size,\r\n",
      "         starting at the minimum size, as given with option -m#)\r\n",
      "-P#      write pattern spectrum to a file\r\n",
      "-Z       print item set statistics (number of item sets per size)\r\n",
      "-g       write output in scanable form (quote certain characters)\r\n",
      "-h#      record header  for output                (default: \"\")\r\n",
      "-k#      item separator for output                (default: \" \")\r\n",
      "-I#      implication sign for sequence rules      (default: \" -> \")\r\n",
      "-v#      output format for sequence information   (default: \" (%S)\")\r\n",
      "-w       integer transaction weight in last field (default: only items)\r\n",
      "-r#      record/transaction separators            (default: \"\\n\")\r\n",
      "-f#      field /item        separators            (default: \" \\t,\")\r\n",
      "-b#      blank   characters                       (default: \" \\t\\r\")\r\n",
      "-C#      comment characters                       (default: \"#\")\r\n",
      "-!       print additional option information\r\n",
      "infile   file to read transactions from           [required]\r\n",
      "outfile  file to write frequent sequences to      [optional]\r\n"
     ]
    }
   ],
   "source": [
    "!./seqwog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding frequent substrings in activities data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./seqwog - find frequent sequences without gaps\r\n",
      "version 3.16 (2016.10.15)        (c) 2010-2016   Christian Borgelt\r\n",
      "reading activities_data.dat ... [3 item(s), 6 transaction(s)] done [0.00s].\r\n",
      "recoding items ... [3 item(s)] done [0.00s].\r\n",
      "reducing and triming transactions ... [6 transaction(s)] done [0.00s].\r\n",
      "writing substring_result ... [7 sequence(s)] done [0.00s].\r\n"
     ]
    }
   ],
   "source": [
    "!./seqwog -ts -s-3 activities_data.dat substring_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 (4)\r\n",
      "2 (5)\r\n",
      "3 1 (3)\r\n",
      "3 2 (3)\r\n",
      "3 (6)\r\n",
      "1 2 (3)\r\n",
      "1 (6)\r\n"
     ]
    }
   ],
   "source": [
    "!cat substring_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 [python/3.5]",
   "language": "python",
   "name": "sys_python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
