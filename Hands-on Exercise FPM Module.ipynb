{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Exercise for  FPM Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring properties of the dataset mushroom_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Questions:** </span> \n",
    "1. How many items are there in the data\n",
    "2. How many transactions are present in the data?\n",
    "3. What is the length of the longest transaction?\n",
    "4. What is the length of the smallest transaction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\r\n"
     ]
    }
   ],
   "source": [
    "!awk -- '{for (i = 1; i <= NF; i++) wc[$i] += 1}; END {print length(wc)}' mushroom_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are 120 items in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8099 mushroom_new.dat\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l mushroom_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are 8099 transactions in this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\r\n",
      "sort: write failed: standard output: Broken pipe\r\n",
      "sort: write error\r\n"
     ]
    }
   ],
   "source": [
    "!awk '{print NF-1}' mushroom_new.dat|sort -k2 -n|head -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Length of the longest transaction is : 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\r\n"
     ]
    }
   ],
   "source": [
    "!awk '{print NF-1}' mushroom_new.dat|sort -k2 -n|tail -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Length of the smallest transaction is : 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3 9 16 24 28 34 37 39 40 53 54 59 63 67 76 85 86 90 94 99 109 114 \r",
      "\r\n",
      "2 3 10 14 23 26 34 36 39 41 52 55 59 63 67 76 85 86 90 93 98 108 114 \r",
      "\r\n",
      "2 4 9 15 23 26 34 36 39 42 52 55 59 63 67 76 85 86 90 93 98 108 115 \r",
      "\r\n",
      "2 4 10 15 23 27 34 36 39 41 52 55 59 63 67 76 85 86 90 93 99 107 115 \r",
      "\r\n",
      "1 3 10 15 23 25 34 36 38 43 52 54 59 63 67 76 85 86 90 93 98 110 114 \r",
      "\r\n",
      "2 4 9 14 23 26 34 36 39 42 52 55 59 63 67 76 85 86 90 93 98 107 115 \r",
      "\r\n",
      "2 3 10 14 23 27 34 36 39 42 52 55 59 63 67 76 85 86 90 93 99 108 114 \r",
      "\r\n",
      "2 3 10 14 23 26 34 36 39 41 52 55 59 63 67 76 85 86 90 93 98 107 115 \r",
      "\r\n",
      "2 4 9 14 23 26 34 36 39 44 52 55 59 63 67 76 85 86 90 93 99 107 114 \r",
      "\r\n",
      "1 3 10 15 23 25 34 36 38 40 52 54 59 63 67 76 85 86 90 93 99 110 113 \r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head mushroom_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the problem setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Questions:** </span> \n",
    "Assume that you run an online store from which customers purchase products. Assume that the transactions in <span style=\"color:blue\">mushroom_new.dat</span> are orders made by your customers over a period of three months. You now learnt itemset mining approaches in your IDA class.\n",
    "\n",
    "1. As someone who runs the online store, hypothetically, what benefit do you see in using itemset mining approaches on this data?\n",
    "2. What type of itemsets (frequent, maximial or closed) would you be interested in discovering this dataset? State your reason.\n",
    "3. What minsup threshold would you use and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans. 1) Could be used for the following purposes:\n",
    "(i) Recommendation to users about other frequent items that are usually brought together. <br> (ii) If the sales of a product goes down, I could announce offer on its other frequent items, so that it lures the customer to the initial product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans. 2)\n",
    "I would be interested to find Closed Itemset, which will serve me 3 things:\n",
    "\n",
    "(i) Save storage/memory in comparision to storing all frequent items. <br>(ii) Closed items will let me know whether a item is frequent or not. <br> (iii) Along with this Frequent/Not-frequent result, it will provide me with the support of that transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans. 3)\n",
    "I will take my initial MinSup = 100. If i get too less frequent itemsets, I would consider reducing the MinSup and if the frequent itemsets are too many then I would increase the MinSup. <br> I dont think there would be any correct answer for this question, the answer completely depends on the purpose and current requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating frequent, maximal and closed itemsets using $\\color{red}{\\text{Apriori}}$, $\\color{red}{\\text{ECLAT}}$, and $\\color{red}{\\text{FPGrowth}}$ algorihtms from the dataset mushroom_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">**Questions:** </span> \n",
    "\n",
    "### 3. Q1. Compare the number of frequent itemsets, using Apriori, for minsup = 10, 100, and 1000. Which of these minsup thresholds results in a maximum number of frequent itemsets? Which of these minsup thresholds results in a least number of frequent itemsets? Provide a rationale for these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x eclat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x fpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x prefixspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x seqwog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.02s].\n",
      "filtering, sorting and recoding items ... [115 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [8099 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [22025 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 done [2.05s].\n",
      "writing mush_AP_Freq_S_10.txt ... [1661968570 set(s)] done [81.48s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -ts -s-10 mushroom_new.dat mush_AP_Freq_S_10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1661968570 mush_AP_Freq_S_10.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l mush_AP_Freq_S_10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [90 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [7931/8099 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [21395 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 done [1.09s].\n",
      "writing mush_AP_Freq_S_100.txt ... [66041020 set(s)] done [2.79s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -ts -s-100 mushroom_new.dat mush_AP_Freq_S_100.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [54 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [5485/8099 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [16872 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 done [0.11s].\n",
      "writing mush_AP_Freq_S_1000.txt ... [123020 set(s)] done [0.01s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -ts -s-1000 mushroom_new.dat mush_AP_Freq_S_1000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ==> MinSup = 10 results in maximum number of frequent itemsets.\n",
    "\n",
    "###### MinSup = 1000 results in minimum number of frequent itemsets.\n",
    "\n",
    "###### This makes complete sense, because there are lesser number of itemsets that have occured atleast 1000(minsup) times than 10(minsup)\n",
    "### ----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Q2. Using Apriori, compare the execution time for finding frequent itemsets for minsup = 10, 100, and 1000. Which of these minsup thresholds takes the least amount of time? Provide a rationale for this observation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ==> MinSup = 1000 takes the least amount of time.  Because there were lesser number  of nodes that went ahead in lattice for further computation. \n",
    "###### ------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Q3. Using Apriori, find the frequent itemsets for minsup = 10, 100, and 1000. Determine the number of itemsets for each size (1 to max length of an itemset). What trends do you see that are common for all three minsup thresholds? What trends do you see that are different? Provide a rationale for these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    114 1\n",
      "   3322 2\n",
      "  45637 3\n",
      " 378479 4\n",
      "2138762 5\n",
      "8839779 6\n",
      "27928520 7\n",
      "69363207 8\n",
      "137810654 9\n",
      "221295967 10\n",
      "288619757 11\n",
      "305859806 12\n",
      "262370292 13\n",
      "180668211 14\n",
      "98486717 15\n",
      "41591107 16\n",
      "13156915 17\n",
      "2952328 18\n",
      " 426335 19\n",
      "  32079 20\n",
      "    582 21\n"
     ]
    }
   ],
   "source": [
    "!awk '{print NF-1}' mush_AP_Freq_S_10.txt|sort -n|uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     89 1\n",
      "   2254 2\n",
      "  25379 3\n",
      " 164683 4\n",
      " 701261 5\n",
      "2122187 6\n",
      "4804699 7\n",
      "8408721 8\n",
      "11598763 9\n",
      "12730357 10\n",
      "11136075 11\n",
      "7723761 12\n",
      "4196361 13\n",
      "1749585 14\n",
      " 541570 15\n",
      " 117817 16\n",
      "  16297 17\n",
      "   1145 18\n",
      "     16 19\n"
     ]
    }
   ],
   "source": [
    "!awk '{print NF-1}' mush_AP_Freq_S_100.txt|sort -n|uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     53 1\n",
      "    641 2\n",
      "   3245 3\n",
      "   9284 4\n",
      "  17323 5\n",
      "  23202 6\n",
      "  23942 7\n",
      "  19922 8\n",
      "  13555 9\n",
      "   7423 10\n",
      "   3166 11\n",
      "   1007 12\n",
      "    224 13\n",
      "     31 14\n",
      "      2 15\n"
     ]
    }
   ],
   "source": [
    "!awk '{print NF-1}' mush_AP_Freq_S_1000.txt|sort -n|uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold\">\n",
    "For all MinSup i.e. 10,100 & 1000, There are comparatively low number of frequent patterns for small itemset sizes. High number of frequent patterns for mid sized item sets, which then gradually goes extremely low for bigger itemset sizes. <br>\n",
    "This is exactly in agreement with the shape of the lattice.\n",
    "</span>\n",
    "\n",
    "<span style=\"font-weight: bold\">\n",
    "Difference is that as we increase the MinSup, the size of itemset drecrease. i.e for MinSup=10 ==> Itemset size = 1 to 21 ||| MinSup=100 ==> Itemset size = 1 to 19 ||| MinSup=1000 ==> Itemset size = 1 to 15.<br>\n",
    "This is because when we increase the MinSup, we prune more nodes that do not satisfy the MinSup and hence the above result.\n",
    "###### -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Q4. Using Apriori, compare the number of frequent, maximal, and closed itemsets. Which is the largest set and which is the smallest set? Provide a rationale for these observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.00s].\n",
      "filtering, sorting and recoding items ... [90 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [7931/8099 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [21395 node(s)] done [0.01s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 done [1.19s].\n",
      "writing <null> ... [66041020 set(s)] done [0.01s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -ts -s-100 mushroom_new.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.00s].\n",
      "filtering, sorting and recoding items ... [90 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [7931/8099 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [21395 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 done [205.52s].\n",
      "filtering for maximal item sets ... done [2.30s].\n",
      "writing <null> ... [5742 set(s)] done [0.88s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -tm -s-100 mushroom_new.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [90 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [7931/8099 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [21395 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 done [210.14s].\n",
      "filtering for closed item sets ... done [2.70s].\n",
      "writing <null> ... [45843 set(s)] done [0.90s].\n"
     ]
    }
   ],
   "source": [
    "!./apriori -tc -s-100 mushroom_new.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-weight: bold\">Frequent Itemset is the largets set </span><br>\n",
    "<span style=\"font-weight: bold\">Maximal Itemset is the smallest set </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Q5. For a minsup = 10, compare the execution time for Apriori, ECLAT and FPGrowth. Which of these algorithms took the least amount of time. Provide a rationale for this observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.00s].\n",
      "filtering, sorting and recoding items ... [115 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [8099 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [22025 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 12 done [2.04s].\n",
      "writing <null> ... [1661968570 set(s)] done [0.08s].\n",
      "2 secs  379180 microsecs\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "start = datetime.datetime.now()\n",
    "!./apriori -ts -s-10 mushroom_new.dat \n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [115 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [8099 transaction(s)] done [0.00s].\n",
      "writing <null> ... [1661968570 set(s)] done [0.18s].\n",
      "0 secs  433330 microsecs\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "!./eclat -ts -s-10 mushroom_new.dat\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.17 (2017.05.30)        (c) 2004-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [115 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [8099 transaction(s)] done [0.01s].\n",
      "writing <null> ... [1661968570 set(s)] done [0.09s].\n",
      "0 secs  354556 microsecs\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "!./fpgrowth -ts -s-10 mushroom_new.dat\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Q6. For a minsup = 100, compare the execution time for Apriori, ECLAT and FPGrowth. Which of these algorithms took the least amount of time. Provide a rationale for this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.00s].\n",
      "filtering, sorting and recoding items ... [90 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [7931/8099 transaction(s)] done [0.01s].\n",
      "building transaction tree ... [21395 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 11 done [1.18s].\n",
      "writing <null> ... [66041020 set(s)] done [0.01s].\n",
      "1 secs  464494 microsecs\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "!./apriori -ts -s-100 mushroom_new.dat \n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [90 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [7931/8099 transaction(s)] done [0.01s].\n",
      "writing <null> ... [66041020 set(s)] done [0.07s].\n",
      "0 secs  249797 microsecs\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "!./eclat -ts -s-100 mushroom_new.dat\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.17 (2017.05.30)        (c) 2004-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [90 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [7931/8099 transaction(s)] done [0.00s].\n",
      "writing <null> ... [66041020 set(s)] done [0.03s].\n",
      "0 secs  235848 microsecs\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "!./fpgrowth -ts -s-100 mushroom_new.dat\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Q7. For a minsup = 1000, compare the execution time for Apriori, ECLAT and FPGrowth. Which of these algorithms took the least amount of time. Provide a rationale for this observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./apriori - find frequent item sets with the apriori algorithm\n",
      "version 6.27 (2017.08.01)        (c) 1996-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [54 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [5485/8099 transaction(s)] done [0.00s].\n",
      "building transaction tree ... [16872 node(s)] done [0.00s].\n",
      "checking subsets of size 1 2 3 4 5 6 7 8 9 10 done [0.11s].\n",
      "writing <null> ... [123020 set(s)] done [0.00s].\n",
      "0 secs  325674 microsecs\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "!./apriori -ts -s-1000 mushroom_new.dat \n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./eclat - find frequent item sets with the eclat algorithm\n",
      "version 5.20 (2017.05.30)        (c) 2002-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.00s].\n",
      "filtering, sorting and recoding items ... [54 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [5485/8099 transaction(s)] done [0.00s].\n",
      "writing <null> ... [123020 set(s)] done [0.02s].\n",
      "0 secs  196118 microsecs\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "!./eclat -ts -s-1000 mushroom_new.dat\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fpgrowth - find frequent item sets with the fpgrowth algorithm\n",
      "version 6.17 (2017.05.30)        (c) 2004-2017   Christian Borgelt\n",
      "reading mushroom_new.dat ... [119 item(s), 8099 transaction(s)] done [0.01s].\n",
      "filtering, sorting and recoding items ... [54 item(s)] done [0.00s].\n",
      "sorting and reducing transactions ... [5485/8099 transaction(s)] done [0.00s].\n",
      "writing <null> ... [123020 set(s)] done [0.00s].\n",
      "0 secs  177718 microsecs\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "!./fpgrowth -ts -s-1000 mushroom_new.dat\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print(elapsed.seconds,\"secs \",elapsed.microseconds,\"microsecs\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Q8. Fill the following table based on execution times computed in (5), (6), and (7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   Algorithm                |minsup=10           |minsup=100          |minsup=1000         |\n",
    "|----------------------------|--------------------|--------------------|--------------------|    \n",
    "|Apriori                     | 2sec 379180ms      | 1sec 464494ms           | 325674ms                  |\n",
    "|Eclat                       | 433330ms            | 249797ms             | 196118ms                   |\n",
    "|FPGrowth                    | 354556ms             | 235848ms             | 177718ms                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Discovering frequent subsequences and substrings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Questions:** </span> \n",
    "Assume that roads in a Cincinnati are assigned numbers. Participants are enrolled in a transportation study and for every trip they make using their car, the sequence of roads taken are recorded. Trips that involves freeways are excluded. This data is in the file <span style=\"color:blue\">road_seq_data.dat</span>.\n",
    "\n",
    "1. What 'type' of sequence mining will you perform to determine frequently taken 'paths'? Paths are sequences of roads traveresed consecutively in the same order.\n",
    "2. How many subsequences are discovered using minsup = 10?\n",
    "3. How many substrings are discovered using minsup = 10?\n",
    "4. Explain the reason for the difference between the results in (2) and (3) above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### According to me mining substring(i.e. without gaps) would be a better option to determine frequently taken paths because it makes much more sence to check for immediate consecutive paths. For Eg. Even if Road1 and Road5 are most frequent, it will not make any sence if they are not directly connected. It would either go like (Road1 --> Road2 --> Road3 --> Road5) OR (Road1 --> Road4 --> Road5). <br>So, its better if we look for Substrings rather than Subsequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrefixSpan version 1.00 - Sequential Pattern Miner\r\n",
      "Written by Yasuo Tabei\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!./prefixspan -min_sup 10 road_seq_data.dat | sed -n 'p;n' > road_data_subsequnce.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4589 road_data_subsequnce.txt\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l road_data_subsequnce.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./seqwog - find frequent sequences without gaps\r\n",
      "version 3.16 (2016.10.15)        (c) 2010-2016   Christian Borgelt\r\n",
      "reading road_seq_data.dat ... [1283 item(s), 1000 transaction(s)] done [0.01s].\r\n",
      "recoding items ... [1283 item(s)] done [0.00s].\r\n",
      "reducing and triming transactions ... [844/1000 transaction(s)] done [0.00s].\r\n",
      "writing road_data_substring_result ... [613 sequence(s)] done [0.00s].\r\n"
     ]
    }
   ],
   "source": [
    "!./seqwog -ts -s-10 road_seq_data.dat road_data_substring_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613 road_data_substring_result\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l road_data_substring_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The difference in result is because; SubSequence checks for item occurance even if they are not consecutive and hence have more results. It is exponential in size on the length of SubSequence <br> On the other hand, SubString looks for immediate occurances. It is polynomial in size on the length of SubString."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
